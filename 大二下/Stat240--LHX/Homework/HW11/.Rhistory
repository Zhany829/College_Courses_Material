knitr::opts_chunk$set(echo = TRUE, message=FALSE, warnings=FALSE)
library(tidyverse)
library(lubridate)
source("../../scripts/viridis.R")
source("../../scripts/ggprob.R")
vb_team <- read_csv("../../data/volleyball-team-2019.csv")
vb_team <- read_csv("../../data/volleyball-team-2019.csv")
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warnings=FALSE)
library(tidyverse)
library(lubridate)
source("../../scripts/viridis.R")
source("../../scripts/ggprob.R")
vb_team <- read_csv("../../data/volleyball-team-2019.csv")
vb_match <- read_csv("../../data/vb-division1-2019-all-matches-corrected.csv") %>%
mutate(index = row_number()) %>%
select(index,everything())
vb_SEC <- vb_team %>%
filter(Conference == "SEC") %>%
mutate(error_per_set = Errors / Sets)
ggplot(vb_SEC, aes(x = error_per_set, y = Win_pct)) +
geom_point() +
geom_smooth(se = FALSE, method = "lm") +
geom_smooth(se = FALSE) +
labs(x = "Errors per Set", y = "Winning Percentage") +
ggtitle("Winning Percentage vs. Errors per Set for the Teams in the SEC Conference")
View(vb_SEC)
# method 1
win <- pull(vb_SEC, Win_pct)
error <- pull(vb_SEC,error_per_set)
win_sd <- sd(win)
error_sd <- sd(error)
r <- cor(error, win)
slope <- r* win_sd / error_sd
slope
win_mean <- mean(win)
error_mean <- mean(error)
intercept <- win_mean - slope * error_mean
intercept
# method 2
coef(lm(Win_pct ~ error_per_set, vb_SEC))
predict <- intercept + slope * 4.5
ggplot(vb_SEC, aes(x = error_per_set, y = Win_pct)) +
geom_point() +
geom_abline(slope = slope, intercept = intercept) +
geom_point(aes(x = 4.5,y = predict), color = "Red")
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
library(tidyverse)
library(lubridate)
source("../../scripts/viridis.R")
source("../../scripts/ggprob.R")
## Read and format the data
chicago <- read_csv2("../../data/chicago-2018.csv") %>%
filter(hour >= "0800 - 0900" & hour <= "1900 - 2000") %>%
select(us_max_wait) %>%
rename(wait = us_max_wait)
## Make a vector with the data we from which we want to sample
chi_wait = chicago %>%
pull(wait)
## Read and format the data
chicago = read_csv2("../../data/chicago-2018.csv") %>%
filter(hour >= "0800 - 0900" & hour <= "1900 - 2000") %>%
select(us_max_wait) %>%
rename(wait = us_max_wait)
## Calculate the population median
chicago %>%
summarize(median = median(wait))
## Use simulation to estimate the sampling distribution of the sample median.
## Make a vector with the data we have from which we want to sample
chi_wait = chicago %>%
pull(wait)
## Create the number of times we want to do the simulation
##   and the sample size as objects in R
B = 10000
n = 10
## Create a container to hold the sample median wait times
median_50 = numeric(B)
## Use a for loop to do the simulation
for ( i in 1:B )
{
median_50[i] = median( sample(chi_wait, n, replace=TRUE) )
}
## The standard deviation of this sample is a numerical estimate of the standard error of the sampling distribution
se_50 = sd(median_50)
se_50
## Make a plot
tibble(median_50) %>%
ggplot(aes(x=median_50)) +
geom_density(fill=viridis3[1]) +
ggtitle("Sample median, n=10",
subtitle="Chicago O'Hare hourly maximum waiting time") +
theme_bw()
mean(abs(median_50 - mean(median_50)) < 1.96*se_50)
## Read and format the data
chicago = read_csv2("../../data/chicago-2018.csv") %>%
filter(hour >= "0800 - 0900" & hour <= "1900 - 2000") %>%
select(us_max_wait) %>%
rename(wait = us_max_wait)
## Calculate the population median
chicago %>%
summarize(median = median(wait))
## Use simulation to estimate the sampling distribution of the sample median.
## Make a vector with the data we have from which we want to sample
chi_wait = chicago %>%
pull(wait)
## Create the number of times we want to do the simulation
##   and the sample size as objects in R
B = 10000
n = 50
## Create a container to hold the sample median wait times
median_50 = numeric(B)
## Use a for loop to do the simulation
for ( i in 1:B )
{
median_50[i] = quantile( sample(chi_wait, n, replace=TRUE), 0.9 )
}
## The standard deviation of this sample is a numerical estimate of the standard error of the sampling distribution
se_50 = sd(median_50)
se_50
## Are about 90% of the sample medians within 1.96 SEs of the mean of this distribution?
#mean(abs(median_50 - mean(median_50)) < 1.65*se_50)
## Make a plot
tibble(median_50) %>%
ggplot(aes(x=median_50)) +
geom_density(fill=viridis3[1]) +
ggtitle("Sample median, n=50",
subtitle="Chicago O'Hare hourly maximum waiting time") +
theme_bw()
df1 = rchisq(100000, 1)
df5 = rchisq(100000, 10)
df10 = rchisq(100000, 50)
dat = tibble(mean_df1 = mean(df1),
mean_df5 = mean(df5),
mean_df10 = mean(df10),
v_df1 = var(df1),
v_df5 = var(df5),
v_df10 = var(df10))
dat
B <- 10000
test_statistic = vector(mode = "numeric", B)
p_value = vector(mode = "numeric", B)
for(i in 1:B){
rchisq_q4 = rchisq(n=50, df=5)
se = sd(rchisq_q4)/sqrt(50)
test_statistic[i] = (mean(rchisq_q4) - 5) / se
p_value[i] = pt(-abs(test_statistic[i]), df=49)
}
p_mean_5 <- mean(p_value<=0.05);p_mean_5
p_mean_1 <- mean(p_value<=0.01);p_mean_1
t <- tibble(test = test_statistic, p = p_value)
gt(49) + geom_density(data = t, aes(x = test))
ggplot(t)+
geom_histogram(aes(x = p), color="black", fill="yellow",boundary=0, binwidth=.1)

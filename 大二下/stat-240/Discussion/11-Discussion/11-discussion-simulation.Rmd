---
title: "STAT 240 Discussion 11"
output: html_document
---

## Members Present
-**Zhan**, WAI ZIN LINN, WILL HU

## Members Absent
-Martin Lozano


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
library(tidyverse)
library(lubridate)
source("../../scripts/viridis.R")
source("../../scripts/ggprob.R")
```

```{r read-data}
## Read and format the data
chicago <- read_csv2("../../data/chicago-2018.csv") %>%
  filter(hour >= "0800 - 0900" & hour <= "1900 - 2000") %>%
  select(us_max_wait) %>%
  rename(wait = us_max_wait)

## Make a vector with the data we from which we want to sample
chi_wait = chicago %>%
  pull(wait)
```

## Problems

### 1

-  For the Chicago wait time data in the example found in the instructions for this assignment, use simulation to find the standard error of the sampling distribution of the sample median if the sample size is $n=10$.  Use `B = 10000` samples.  
-  Plot a density estimate of the simulated sampling distribution.
```{r problem-1}
## Read and format the data
chicago = read_csv2("../../data/chicago-2018.csv") %>%
  filter(hour >= "0800 - 0900" & hour <= "1900 - 2000") %>%
  select(us_max_wait) %>%
  rename(wait = us_max_wait)

## Calculate the population median
chicago %>%
  summarize(median = median(wait))

## Use simulation to estimate the sampling distribution of the sample median.

## Make a vector with the data we have from which we want to sample
chi_wait = chicago %>%
  pull(wait)

## Create the number of times we want to do the simulation
##   and the sample size as objects in R
B = 10000
n = 10

## Create a container to hold the sample median wait times
median_50 = numeric(B)

## Use a for loop to do the simulation
for ( i in 1:B )
{
  median_50[i] = median( sample(chi_wait, n, replace=TRUE) )
}

## The standard deviation of this sample is a numerical estimate of the standard error of the sampling distribution
se_50 = sd(median_50)
se_50

## Make a plot
tibble(median_50) %>%
ggplot(aes(x=median_50)) +
  geom_density(fill=viridis3[1]) +
  ggtitle("Sample median, n=10",
          subtitle="Chicago O'Hare hourly maximum waiting time") +
  theme_bw()
```
Describe the shape of the sampling distribution (e.g., where is the mode or modes? is the density symmetric or skewed)?  

**Response:** It's skewed to the right. The mode seems to be around 40 (where the graph is spiked). 
Are about 95% of the observations within 1.96 standard errors of the distribution?

```{r}
mean(abs(median_50 - mean(median_50)) < 1.96*se_50)
```
**Response:** Yes. 


### 2

Repeat problem 1, but instead of investigating the sampling distribution of the sample median if the sample is n=10, consider the sampling distribution of the 0.90 quantile if a sample of size n=50.

```{r problem-2}
## Read and format the data
chicago = read_csv2("../../data/chicago-2018.csv") %>%
  filter(hour >= "0800 - 0900" & hour <= "1900 - 2000") %>%
  select(us_max_wait) %>%
  rename(wait = us_max_wait)

## Calculate the population median
chicago %>%
  summarize(median = median(wait))

## Use simulation to estimate the sampling distribution of the sample median.

## Make a vector with the data we have from which we want to sample
chi_wait = chicago %>%
  pull(wait)

## Create the number of times we want to do the simulation
##   and the sample size as objects in R
B = 10000
n = 50

## Create a container to hold the sample median wait times
median_50 = numeric(B)

## Use a for loop to do the simulation
for ( i in 1:B )
{
  median_50[i] = quantile( sample(chi_wait, n, replace=TRUE), 0.9 )
}

## The standard deviation of this sample is a numerical estimate of the standard error of the sampling distribution
se_50 = sd(median_50)
se_50

## Are about 90% of the sample medians within 1.96 SEs of the mean of this distribution?
#mean(abs(median_50 - mean(median_50)) < 1.65*se_50)

## Make a plot
tibble(median_50) %>%
ggplot(aes(x=median_50)) +
  geom_density(fill=viridis3[1]) +
  ggtitle("Sample median, n=50",
          subtitle="Chicago O'Hare hourly maximum waiting time") +
  theme_bw()
```
**Response:**The shape of the sampling distribution is a bimodal distribution, but skews slightly to the right. The graph dips and then spikes at 83. The modes are 78 and 83.

```{r}
mean(abs(median_50 - mean(median_50)) < 1.96*se_50)
```

**Response:** About 95% of the observations within 1.96 standard errors of the distribution
### 3

Theory informs us that the mean and variance of a chi-square distribution with $v$ degrees of freedom are $v$ and $2v$, respectively. 

- Use the function `rchisq()` to take samples of size 100,000 random chi-square random variables when $v$ is 1, 10, and 50.  
-  Are your results consistent with theory?  Use `mean()` and `var()` to calculate the mean and variance of the samples and compare to the theoretical values.

- The results are consistent with the theory. 

```{r problem-3}
df1 = rchisq(100000, 1)

df5 = rchisq(100000, 10)

df10 = rchisq(100000, 50)

dat = tibble(mean_df1 = mean(df1),
             mean_df5 = mean(df5),
             mean_df10 = mean(df10),
             v_df1 = var(df1),
             v_df5 = var(df5),
             v_df10 = var(df10))

dat
```



### 4

In this question, we are going to carryout a simulation to help us understand the interpretation of the p-value cutoff in a hypothesis test.  This cutoff is referred to as the *significance level*, and common significance levels are 0.05 and 0.01.  When a p-value is less than or equal to the significance level, we reject the null hypothesis.

We will investigate the following hypotheses:

$$
H_0: \mu = 5 \\
H_a: \mu \neq 5
$$

where $\mu$ is the mean of the random variable $X$.  Suppose X ~ Chi-square($\mu$).  (Recall that the mean of a chi-square distribution is equal to its degrees of freedom.)

In this simulation study, we are going to assume that the null hypothesis is true.  That is, we are going to assume that X ~ Chi-square(5) and determine the proportion of times we reject the null hypothesis, even though it is true, when the significance level is set to 0.05.

To carryout this simulation study, do the following and then address the questions below.

-  Generate a sample of size n = 50 values from a Chi-square distribution with 5 degrees of freedom.  
-  Compute an appropriate test statistic for the hypothesis test noted above.  
-  Calculate the p-value for this test.  
-  Repeat these steps 10,000 times, and store the test statistics values in a variable called `test_stat` and store the p-values in a variable called `pvals`.

```{r}
B <- 10000
test_statistic = vector(mode = "numeric", B)
p_value = vector(mode = "numeric", B)
for(i in 1:B){
  rchisq_q4 = rchisq(n=50, df=5)
  se = sd(rchisq_q4)/sqrt(50)
  test_statistic[i] = (mean(rchisq_q4) - 5) / se
  p_value[i] = pt(-abs(test_statistic[i]), df=49)
}

p_mean_5 <- mean(p_value<=0.05);p_mean_5
p_mean_1 <- mean(p_value<=0.01);p_mean_1
t <- tibble(test = test_statistic, p = p_value)

```
What proportion of the 10,000 tests were rejected?  Is this what you expected?  Explain.

- 10.44% of the 10,000 tests were rejected when the significance level is set to 0.05. 2.38% of the 10,000 tests were rejected when the significance level is set to 0.01.


Create a graphic to display a density estimate of the 10,000 simulated test statistics and compare this to the density of a t-distribution with 50-1 degrees of freedom (you may use `geom_t_density()` from the ggprob.R script).  How do these densities compare?  Is this what you expected?  Explain.

```{r}
gt(49) + geom_density(data = t, aes(x = test)) 
```


Create a graphic to display a histogram of the 10,000 simulated p-values.  For the histogram, use the following specifications:  `color="black", fill="yellow",boundary=0, binwidth=.1`.  Describe the shape of the resulting histogram.

```{r}
ggplot(t)+
geom_histogram(aes(x = p), color="black", fill="yellow",boundary=0, binwidth=.1)
```

- The histogram is roughly normally distributed and forms a bell curve.
